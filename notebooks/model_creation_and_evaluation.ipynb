{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a93c0f",
   "metadata": {},
   "source": [
    "## Model Creation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2c0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Load feature_selection-engineering file\n",
    "%run feature_selection-engineering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a774a3",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1392d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dependent and independent variables\n",
    "X = traffic_data[[ \"Year\", \"Month\", \"DayOfWeek\", \"HourOfDay\", \"Junction\"]]\n",
    "y = traffic_data[[\"Vehicles\"]]\n",
    "\n",
    "#Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d1d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def model_eval(model_name):\n",
    "    model = model_name #Assign the model\n",
    "    model.fit(X_train, y_train) #Fit the model\n",
    "    \n",
    "    #Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #Different metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred)) #Calculate the RMSE\n",
    "    r2 = r2_score(y_test, y_pred) #Calculate the R-squared\n",
    "    mae = mean_absolute_error(y_test, y_pred) #Calculate MAE\n",
    "\n",
    "    #Print the results\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"R-squared: \", r2)\n",
    "    print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74359fc5",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8fb860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.046367826810308\n",
      "R-squared:  0.9316728843005203\n",
      "MAE:  3.36985913373724\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "model_eval(XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a798d",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120b95fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.543637380216312\n",
      "R-squared:  0.9446085657888055\n",
      "MAE:  2.9751357846113913\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "model_eval(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7433eec3",
   "metadata": {},
   "source": [
    "#### LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73878da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 38496, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.863407\n",
      "RMSE:  5.897020920200154\n",
      "R-squared:  0.9066959233210862\n",
      "MAE:  3.9833544724937546\n"
     ]
    }
   ],
   "source": [
    "#LGBMRegressor\n",
    "model_eval(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783ce17",
   "metadata": {},
   "source": [
    "### With dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b170ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into train and test\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a712c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def new_model_eval(model_name):\n",
    "    model = model_name #Assign the model\n",
    "    model.fit(new_X_train, new_y_train) #Fit the model\n",
    "    \n",
    "    #Make predictions on the test set\n",
    "    new_y_pred = model.predict(new_X_test)\n",
    "\n",
    "    #Different metrics\n",
    "    rmse = np.sqrt(mean_squared_error(new_y_test, new_y_pred)) #Calculate the RMSE\n",
    "    r2 = r2_score(new_y_test, new_y_pred) #Calculate the R-squared\n",
    "    mae = mean_absolute_error(new_y_test, new_y_pred) #Calculate MAE\n",
    "\n",
    "    #Print the results\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"R-squared: \", r2)\n",
    "    print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a531e9",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579ec770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.5934440588926435\n",
      "R-squared:  0.916055184190329\n",
      "MAE:  3.764442518738149\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "new_model_eval(XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc9e37",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e0ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.913429415726535\n",
      "R-squared:  0.9352254021079539\n",
      "MAE:  3.222777694006845\n"
     ]
    }
   ],
   "source": [
    "#RanadomForest\n",
    "new_model_eval(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be69ba",
   "metadata": {},
   "source": [
    "#### LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e5b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 38496, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.863407\n",
      "RMSE:  6.071745192771964\n",
      "R-squared:  0.9010849538732142\n",
      "MAE:  4.135102803829889\n"
     ]
    }
   ],
   "source": [
    "#LGBMRegressor\n",
    "new_model_eval(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec8af8",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f540769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the cross-validation method\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "def cv_model_eval(model):\n",
    "    #Use cross-validation to evaluate the model\n",
    "    scores = cross_val_score(model, X, y, cv = kfold, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "    #Calculate the RMSE, R-squared, and MAE\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    r2 = cross_val_score(model, X, y, cv=kfold, scoring='r2').mean()\n",
    "    mae = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "    #Print the results\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"R-squared: \", r2)\n",
    "    print(\"MAE: \", -mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380938c9",
   "metadata": {},
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b428e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.113697453557049\n",
      "R-squared:  0.9331755953442382\n",
      "MAE:  3.386168236494238\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "cv_model_eval(XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2180f",
   "metadata": {},
   "source": [
    "#### RanadomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3699403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.5249271200208625\n",
      "R-squared:  0.9472842058972567\n",
      "MAE:  2.927437008648471\n"
     ]
    }
   ],
   "source": [
    "#RanadomForest\n",
    "cv_model_eval(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c672d2d",
   "metadata": {},
   "source": [
    "#### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26eb8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ad6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.844718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.797708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.844718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.797708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.844718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.797708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "RMSE:  5.925133357939748\n",
      "R-squared:  0.910261026642319\n",
      "MAE:  3.999896607097547\n"
     ]
    }
   ],
   "source": [
    "#LGBMRegressor\n",
    "cv_model_eval(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a0bf2",
   "metadata": {},
   "source": [
    "### With dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1619576",
   "metadata": {},
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9582151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the cross-validation method\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "def cv_model_eval_d(model):\n",
    "    #Use cross-validation to evaluate the model\n",
    "    scores = cross_val_score(model, new_X, new_y, cv = kfold, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "    #Calculate the RMSE, R-squared, and MAE\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    r2 = cross_val_score(model,new_X, new_y, cv=kfold, scoring='r2').mean()\n",
    "    mae = cross_val_score(model, new_X, new_y, cv=kfold, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "    #Print the results\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"R-squared: \", r2)\n",
    "    print(\"MAE: \", -mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3363480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.72827796050781\n",
      "R-squared:  0.9161441948318643\n",
      "MAE:  3.8506377245752335\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "cv_model_eval_d(XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9023d5",
   "metadata": {},
   "source": [
    "#### RanadomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b19c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.968155442034164\n",
      "R-squared:  0.9368958126762756\n",
      "MAE:  3.210981798930902\n"
     ]
    }
   ],
   "source": [
    "#RanadomForest\n",
    "cv_model_eval_d(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a59534",
   "metadata": {},
   "source": [
    "#### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9e4d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.844718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.797708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.844718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.797708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.844718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.797708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.749151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.794822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.777771\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.758434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.816151\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.787493\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.783673\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 43308, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 21.764651\n",
      "RMSE:  6.061416699981459\n",
      "R-squared:  0.9060839938811757\n",
      "MAE:  4.131741881255522\n"
     ]
    }
   ],
   "source": [
    "#LGBMRegressor\n",
    "cv_model_eval_d(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c68bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
